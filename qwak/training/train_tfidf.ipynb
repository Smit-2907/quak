{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Recipe Recommendation Model Training\n",
    "\n",
    "This notebook trains a TF-IDF based recommendation model for recipe matching based on ingredients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned recipe data\n",
    "df = pd.read_csv('recipes_cleaned.csv')\n",
    "print(f\"Loaded {len(df)} recipes\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ingredient text for TF-IDF\n",
    "# Use the cleaned ingredients column\n",
    "ingredient_texts = df['ingredients_cleaned'].fillna('').tolist()\n",
    "print(f\"Sample ingredient text: {ingredient_texts[0]}\")\n",
    "print(f\"Total recipes with ingredients: {len([x for x in ingredient_texts if x])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF vectorizer with appropriate parameters\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    token_pattern=r'[a-zA-Z]+',  # Only alphabetic tokens\n",
    "    stop_words=None,  # We already cleaned stop ingredients\n",
    "    max_features=5000,  # Limit vocabulary size\n",
    "    min_df=2,  # Ignore terms that appear in less than 2 documents\n",
    "    max_df=0.8,  # Ignore terms that appear in more than 80% of documents\n",
    "    ngram_range=(1, 2)  # Use unigrams and bigrams\n",
    ")\n",
    "\n",
    "print(\"Training TF-IDF vectorizer...\")\n",
    "tfidf_matrix = vectorizer.fit_transform(ingredient_texts)\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some vocabulary examples\n",
    "vocab_items = list(vectorizer.vocabulary_.items())\n",
    "vocab_items.sort(key=lambda x: x[1])  # Sort by index\n",
    "print(\"Sample vocabulary (first 20 terms):\")\n",
    "for term, idx in vocab_items[:20]:\n",
    "    print(f\"  {idx}: {term}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Cosine Similarity Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test similarity computation with a sample query\n",
    "def test_similarity(query_ingredients, top_n=5):\n",
    "    \"\"\"Test similarity computation for given ingredients\"\"\"\n",
    "    # Transform query ingredients\n",
    "    query_text = ','.join(query_ingredients)\n",
    "    query_vector = vectorizer.transform([query_text])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get top matches\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    print(f\"Query ingredients: {query_ingredients}\")\n",
    "    print(f\"Top {top_n} matches:\")\n",
    "    for i, idx in enumerate(top_indices):\n",
    "        recipe = df.iloc[idx]\n",
    "        score = similarities[idx]\n",
    "        print(f\"  {i+1}. {recipe['title']} (Score: {score:.3f})\")\n",
    "        print(f\"     Ingredients: {recipe['ingredients_cleaned']}\")\n",
    "    \n",
    "    return similarities, top_indices\n",
    "\n",
    "# Test with sample ingredients\n",
    "test_ingredients = ['chicken', 'tomato', 'garlic']\n",
    "similarities, top_indices = test_similarity(test_ingredients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "models_dir = Path('../backend/models')\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the trained vectorizer\n",
    "vectorizer_path = models_dir / 'vectorizer.pkl'\n",
    "with open(vectorizer_path, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(f\"Saved vectorizer to {vectorizer_path}\")\n",
    "\n",
    "# Save the TF-IDF vectors\n",
    "vectors_path = models_dir / 'recipe_vectors_tfidf.npz'\n",
    "np.savez_compressed(vectors_path, vectors=tfidf_matrix.toarray())\n",
    "print(f\"Saved TF-IDF vectors to {vectors_path}\")\n",
    "\n",
    "# Save recipe metadata for quick lookup\n",
    "metadata_path = models_dir / 'recipe_metadata.pkl'\n",
    "recipe_metadata = df[['id', 'title', 'ingredients_cleaned', 'cuisine', 'diet_types', 'cooking_time', 'difficulty']].to_dict('records')\n",
    "with open(metadata_path, 'wb') as f:\n",
    "    pickle.dump(recipe_metadata, f)\n",
    "print(f\"Saved recipe metadata to {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TF-IDF Model Training Summary ===\")\n",
    "print(f\"Total recipes processed: {len(df)}\")\n",
    "print(f\"TF-IDF matrix shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "print(f\"Matrix sparsity: {(1 - tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1])) * 100:.2f}%\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - {vectorizer_path}\")\n",
    "print(f\"  - {vectors_path}\")\n",
    "print(f\"  - {metadata_path}\")\n",
    "print(\"\\nModel ready for deployment!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}